{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LightGBM with Feature Engineering and Interaction Testing\n",
        "## Travelers UMC 2025 Competition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "LightGBM Model with Feature Engineering and Interaction Testing\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# LightGBM with Feature Engineering and Interaction Testing\n",
        "# Travelers UMC 2025 Competition\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data handling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import (roc_auc_score, f1_score, precision_score, recall_score, \n",
        "                            classification_report, average_precision_score)\n",
        "\n",
        "# LightGBM\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Hyperparameter optimization\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from itertools import combinations\n",
        "\n",
        "# Progress bar\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"LightGBM Model with Feature Engineering and Interaction Testing\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING DATA\n",
            "================================================================================\n",
            "Original data shape: (17999, 29)\n",
            "\n",
            "Columns: ['subrogation', 'claim_number', 'year_of_born', 'gender', 'email_or_tel_available', 'safety_rating', 'annual_income', 'high_education_ind', 'address_change_ind', 'living_status', 'zip_code', 'claim_date', 'claim_day_of_week', 'accident_site', 'past_num_of_claims', 'witness_present_ind', 'liab_prct', 'channel', 'policy_report_filed_ind', 'claim_est_payout', 'vehicle_made_year', 'vehicle_category', 'vehicle_price', 'vehicle_color', 'vehicle_weight', 'age_of_DL', 'accident_type', 'in_network_bodyshop', 'vehicle_mileage']\n",
            "\n",
            "Data types:\n",
            "subrogation                  int64\n",
            "claim_number                 int64\n",
            "year_of_born                 int64\n",
            "gender                      object\n",
            "email_or_tel_available       int64\n",
            "safety_rating                int64\n",
            "annual_income                int64\n",
            "high_education_ind           int64\n",
            "address_change_ind           int64\n",
            "living_status               object\n",
            "zip_code                     int64\n",
            "claim_date                  object\n",
            "claim_day_of_week           object\n",
            "accident_site               object\n",
            "past_num_of_claims           int64\n",
            "witness_present_ind         object\n",
            "liab_prct                    int64\n",
            "channel                     object\n",
            "policy_report_filed_ind      int64\n",
            "claim_est_payout           float64\n",
            "vehicle_made_year            int64\n",
            "vehicle_category            object\n",
            "vehicle_price              float64\n",
            "vehicle_color               object\n",
            "vehicle_weight             float64\n",
            "age_of_DL                    int64\n",
            "accident_type               object\n",
            "in_network_bodyshop         object\n",
            "vehicle_mileage              int64\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "0\n",
            "\n",
            "First few rows:\n",
            "   subrogation  claim_number  year_of_born gender  email_or_tel_available  \\\n",
            "0            1       6090851          1990      F                       0   \n",
            "1            0       4653734          1972      F                       1   \n",
            "2            0       1014777          2003      F                       1   \n",
            "3            1       8101873          1983      F                       1   \n",
            "4            0       5081870          1985      F                       1   \n",
            "\n",
            "   safety_rating  annual_income  high_education_ind  address_change_ind  \\\n",
            "0             75          70966                   1                   1   \n",
            "1             94          79723                   1                   1   \n",
            "2             76          41527                   1                   1   \n",
            "3             54          42099                   1                   1   \n",
            "4             54          47206                   1                   1   \n",
            "\n",
            "  living_status  ...  claim_est_payout vehicle_made_year vehicle_category  \\\n",
            "0          Rent  ...           3218.84              2021            Large   \n",
            "1          Rent  ...           1338.52              2025           Medium   \n",
            "2           Own  ...           3540.05              2022          Compact   \n",
            "3          Rent  ...           1507.94              2025           Medium   \n",
            "4           Own  ...           5080.63              2021          Compact   \n",
            "\n",
            "  vehicle_price  vehicle_color vehicle_weight  age_of_DL  \\\n",
            "0   16272.12725            red    21620.79697         25   \n",
            "1   34102.78197         silver    10840.58520         23   \n",
            "2   15000.00000         silver    24318.12282         23   \n",
            "3   16984.45295          white    36958.26656         23   \n",
            "4   46545.72863           blue    11779.17422         17   \n",
            "\n",
            "           accident_type  in_network_bodyshop  vehicle_mileage  \n",
            "0    multi_vehicle_clear                   no            75421  \n",
            "1    multi_vehicle_clear                  yes            31988  \n",
            "2  multi_vehicle_unclear                  yes            60876  \n",
            "3  multi_vehicle_unclear                  yes           152772  \n",
            "4    multi_vehicle_clear                  yes            41151  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 1: Load Data\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_df = pd.read_csv('Data/Training_TriGuard.csv')\n",
        "\n",
        "print(f\"Original data shape: {train_df.shape}\")\n",
        "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
        "print(f\"\\nData types:\\n{train_df.dtypes}\")\n",
        "print(f\"\\nMissing values:\\n{train_df.isnull().sum().sum()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Data Preprocessing and Date-based Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "DATA PREPROCESSING AND DATE-BASED SPLIT\n",
            "================================================================================\n",
            "Date range: 2015-01-01 00:00:00 to 2016-12-31 00:00:00\n",
            "\n",
            "Split date (80th percentile): 2016-08-01 00:00:00\n",
            "\n",
            "Training set: 14372 samples (2015-01-01 00:00:00 to 2016-07-31 00:00:00)\n",
            "Validation set: 3627 samples (2016-08-01 00:00:00 to 2016-12-31 00:00:00)\n",
            "\n",
            "Training features shape: (14372, 26)\n",
            "Validation features shape: (3627, 26)\n",
            "\n",
            "Class distribution in training:\n",
            "subrogation\n",
            "0    0.772474\n",
            "1    0.227526\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution in validation:\n",
            "subrogation\n",
            "0    0.767025\n",
            "1    0.232975\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 2: Data Preprocessing and Date-based Split\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA PREPROCESSING AND DATE-BASED SPLIT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert claim_date to datetime\n",
        "train_df['claim_date'] = pd.to_datetime(train_df['claim_date'])\n",
        "\n",
        "# Sort by date\n",
        "train_df = train_df.sort_values('claim_date').reset_index(drop=True)\n",
        "\n",
        "# Display date range\n",
        "print(f\"Date range: {train_df['claim_date'].min()} to {train_df['claim_date'].max()}\")\n",
        "\n",
        "# Split by date (e.g., use 80% for training, 20% for validation)\n",
        "# This prevents data leakage by ensuring future data is not used to predict past\n",
        "split_date = train_df['claim_date'].quantile(0.8)\n",
        "print(f\"\\nSplit date (80th percentile): {split_date}\")\n",
        "\n",
        "train_data = train_df[train_df['claim_date'] < split_date].copy()\n",
        "val_data = train_df[train_df['claim_date'] >= split_date].copy()\n",
        "\n",
        "print(f\"\\nTraining set: {train_data.shape[0]} samples ({train_data['claim_date'].min()} to {train_data['claim_date'].max()})\")\n",
        "print(f\"Validation set: {val_data.shape[0]} samples ({val_data['claim_date'].min()} to {val_data['claim_date'].max()})\")\n",
        "\n",
        "# Store claim numbers for later\n",
        "train_claim_numbers = train_data['claim_number'].copy()\n",
        "val_claim_numbers = val_data['claim_number'].copy()\n",
        "\n",
        "# Separate features and target\n",
        "X_train_raw = train_data.drop(['subrogation', 'claim_number', 'claim_date'], axis=1, errors='ignore')\n",
        "y_train = train_data['subrogation'].astype(int)\n",
        "\n",
        "X_val_raw = val_data.drop(['subrogation', 'claim_number', 'claim_date'], axis=1, errors='ignore')\n",
        "y_val = val_data['subrogation'].astype(int)\n",
        "\n",
        "print(f\"\\nTraining features shape: {X_train_raw.shape}\")\n",
        "print(f\"Validation features shape: {X_val_raw.shape}\")\n",
        "print(f\"\\nClass distribution in training:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(f\"\\nClass distribution in validation:\")\n",
        "print(y_val.value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "FEATURE ENGINEERING\n",
            "================================================================================\n",
            "Categorical columns: ['gender', 'living_status', 'claim_day_of_week', 'accident_site', 'witness_present_ind', 'channel', 'vehicle_category', 'vehicle_color', 'accident_type', 'in_network_bodyshop']\n",
            "Numerical columns: 16\n",
            "Categorical columns: ['gender', 'living_status', 'claim_day_of_week', 'accident_site', 'witness_present_ind', 'channel', 'vehicle_category', 'vehicle_color', 'accident_type', 'in_network_bodyshop']\n",
            "Numerical columns: 16\n",
            "\n",
            "After preprocessing:\n",
            "Training features shape: (14372, 41)\n",
            "Validation features shape: (3627, 41)\n",
            "Feature names: ['address_change_ind', 'claim_day_of_week_Sunday', 'vehicle_made_year', 'in_network_bodyshop_yes', 'accident_type_multi_vehicle_unclear', 'witness_present_ind_Y', 'year_of_born', 'age_of_DL', 'channel_Online', 'accident_site_Local', 'liab_prct', 'policy_report_filed_ind', 'living_status_Rent', 'claim_day_of_week_Tuesday', 'channel_Phone', 'vehicle_color_gray', 'past_num_of_claims', 'claim_day_of_week_Saturday', 'vehicle_color_white', 'accident_site_Unknown', 'vehicle_category_Medium', 'vehicle_color_other', 'accident_type_single_car', 'vehicle_category_Large', 'claim_day_of_week_Wednesday', 'safety_rating', 'email_or_tel_available', 'vehicle_color_silver', 'high_education_ind', 'vehicle_mileage', 'gender_M', 'accident_site_Parking Area', 'vehicle_color_red', 'zip_code', 'vehicle_color_blue', 'claim_day_of_week_Monday', 'vehicle_price', 'claim_est_payout', 'annual_income', 'claim_day_of_week_Thursday', 'vehicle_weight']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 3: Feature Engineering - Handle Categorical and Numerical Features\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FEATURE ENGINEERING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def preprocess_features(df):\n",
        "    \"\"\"Preprocess features: encode categorical, handle missing values\"\"\"\n",
        "    df_processed = df.copy()\n",
        "    \n",
        "    # Identify categorical columns\n",
        "    categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
        "    numerical_cols = df_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    \n",
        "    print(f\"Categorical columns: {categorical_cols}\")\n",
        "    print(f\"Numerical columns: {len(numerical_cols)}\")\n",
        "    \n",
        "    # Fill missing values\n",
        "    for col in numerical_cols:\n",
        "        if df_processed[col].isnull().sum() > 0:\n",
        "            df_processed[col].fillna(df_processed[col].median(), inplace=True)\n",
        "    \n",
        "    for col in categorical_cols:\n",
        "        if df_processed[col].isnull().sum() > 0:\n",
        "            df_processed[col].fillna('Unknown', inplace=True)\n",
        "    \n",
        "    # One-hot encode categorical variables\n",
        "    if categorical_cols:\n",
        "        df_processed = pd.get_dummies(df_processed, columns=categorical_cols, drop_first=True)\n",
        "    \n",
        "    return df_processed, categorical_cols, numerical_cols\n",
        "\n",
        "# Preprocess training and validation sets\n",
        "X_train_processed, cat_cols, num_cols = preprocess_features(X_train_raw)\n",
        "X_val_processed, _, _ = preprocess_features(X_val_raw)\n",
        "\n",
        "# Ensure both sets have the same columns\n",
        "common_cols = list(set(X_train_processed.columns) & set(X_val_processed.columns))\n",
        "X_train_processed = X_train_processed[common_cols]\n",
        "X_val_processed = X_val_processed[common_cols]\n",
        "\n",
        "# Add missing columns as zeros\n",
        "for col in X_train_processed.columns:\n",
        "    if col not in X_val_processed.columns:\n",
        "        X_val_processed[col] = 0\n",
        "for col in X_val_processed.columns:\n",
        "    if col not in X_train_processed.columns:\n",
        "        X_train_processed[col] = 0\n",
        "\n",
        "X_val_processed = X_val_processed[X_train_processed.columns]\n",
        "\n",
        "print(f\"\\nAfter preprocessing:\")\n",
        "print(f\"Training features shape: {X_train_processed.shape}\")\n",
        "print(f\"Validation features shape: {X_val_processed.shape}\")\n",
        "print(f\"Feature names: {list(X_train_processed.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Apply Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "APPLYING SCALING\n",
            "================================================================================\n",
            "Scaled training features shape: (14372, 41)\n",
            "Scaled validation features shape: (3627, 41)\n",
            "\n",
            "Scaled feature statistics (first 5 features):\n",
            "       address_change_ind  claim_day_of_week_Sunday  vehicle_made_year  \\\n",
            "count        14372.000000              14372.000000       14372.000000   \n",
            "mean            -0.407946                  0.140551          -0.138725   \n",
            "std              0.491470                  0.347570           0.969266   \n",
            "min             -1.000000                  0.000000          -5.000000   \n",
            "25%             -1.000000                  0.000000          -0.500000   \n",
            "50%              0.000000                  0.000000           0.000000   \n",
            "75%              0.000000                  0.000000           0.500000   \n",
            "max              0.000000                  1.000000           1.000000   \n",
            "\n",
            "       in_network_bodyshop_yes  accident_type_multi_vehicle_unclear  \n",
            "count             14372.000000                         14372.000000  \n",
            "mean                 -0.274631                             0.364807  \n",
            "std                   0.446344                             0.481393  \n",
            "min                  -1.000000                             0.000000  \n",
            "25%                  -1.000000                             0.000000  \n",
            "50%                   0.000000                             0.000000  \n",
            "75%                   0.000000                             1.000000  \n",
            "max                   0.000000                             1.000000  \n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 4: Apply Scaling\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"APPLYING SCALING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Use RobustScaler (less sensitive to outliers) or StandardScaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Fit on training data only\n",
        "X_train_scaled = pd.DataFrame(\n",
        "    scaler.fit_transform(X_train_processed),\n",
        "    columns=X_train_processed.columns,\n",
        "    index=X_train_processed.index\n",
        ")\n",
        "\n",
        "# Transform validation data\n",
        "X_val_scaled = pd.DataFrame(\n",
        "    scaler.transform(X_val_processed),\n",
        "    columns=X_val_processed.columns,\n",
        "    index=X_val_processed.index\n",
        ")\n",
        "\n",
        "print(f\"Scaled training features shape: {X_train_scaled.shape}\")\n",
        "print(f\"Scaled validation features shape: {X_val_scaled.shape}\")\n",
        "print(f\"\\nScaled feature statistics (first 5 features):\")\n",
        "print(X_train_scaled.iloc[:, :5].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Base LightGBM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "BASE LIGHTGBM MODEL\n",
            "================================================================================\n",
            "Training base LightGBM model...\n",
            "Parameters: {'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt', 'num_leaves': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1, 'n_estimators': 10000, 'max_depth': -1, 'min_child_samples': 20, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'is_unbalance': True, 'random_state': 42}\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\ttrain's auc: 0.897628\tval's auc: 0.837369\n",
            "[200]\ttrain's auc: 0.936255\tval's auc: 0.83723\n",
            "Early stopping, best iteration is:\n",
            "[96]\ttrain's auc: 0.895718\tval's auc: 0.837971\n",
            "\n",
            "================================================================================\n",
            "BASE MODEL RESULTS\n",
            "================================================================================\n",
            "Training F1: 0.659226\n",
            "Validation F1: 0.596457\n",
            "Training AUC: 0.895718\n",
            "Validation AUC: 0.837971\n",
            "Optimal threshold: 0.5500\n",
            "Best iteration: 96\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "                                feature    importance\n",
            "10                            liab_prct  36295.765280\n",
            "22             accident_type_single_car  17185.042723\n",
            "5                 witness_present_ind_Y   6085.771494\n",
            "19                accident_site_Unknown   3942.879620\n",
            "31           accident_site_Parking Area   3813.452265\n",
            "29                      vehicle_mileage   3347.095395\n",
            "33                             zip_code   3063.004586\n",
            "40                       vehicle_weight   3047.790949\n",
            "4   accident_type_multi_vehicle_unclear   2841.408605\n",
            "37                     claim_est_payout   2492.400207\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 5: Base LightGBM Model\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BASE LIGHTGBM MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Base LightGBM parameters with high iterations\n",
        "base_params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1,\n",
        "    'n_estimators': 10000,  # High number of iterations\n",
        "    'max_depth': -1,\n",
        "    'min_child_samples': 20,\n",
        "    'reg_alpha': 0.1,\n",
        "    'reg_lambda': 0.1,\n",
        "    'is_unbalance': True,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "print(\"Training base LightGBM model...\")\n",
        "print(f\"Parameters: {base_params}\")\n",
        "\n",
        "# Create LightGBM datasets\n",
        "train_data_lgb = lgb.Dataset(X_train_scaled, label=y_train)\n",
        "val_data_lgb = lgb.Dataset(X_val_scaled, label=y_val, reference=train_data_lgb)\n",
        "\n",
        "# Train with early stopping\n",
        "base_model = lgb.train(\n",
        "    base_params,\n",
        "    train_data_lgb,\n",
        "    valid_sets=[train_data_lgb, val_data_lgb],\n",
        "    valid_names=['train', 'val'],\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=200, verbose=True),\n",
        "        lgb.log_evaluation(period=100)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Make predictions (probabilities)\n",
        "y_train_pred_base_proba = base_model.predict(X_train_scaled, num_iteration=base_model.best_iteration)\n",
        "y_val_pred_base_proba = base_model.predict(X_val_scaled, num_iteration=base_model.best_iteration)\n",
        "\n",
        "# Find optimal threshold for F1 score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def find_optimal_threshold(y_true, y_proba):\n",
        "    \"\"\"Find threshold that maximizes F1 score\"\"\"\n",
        "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
        "    f1_scores = []\n",
        "    for threshold in thresholds:\n",
        "        y_pred_binary = (y_proba >= threshold).astype(int)\n",
        "        f1 = f1_score(y_true, y_pred_binary)\n",
        "        f1_scores.append(f1)\n",
        "    optimal_idx = np.argmax(f1_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    optimal_f1 = f1_scores[optimal_idx]\n",
        "    return optimal_threshold, optimal_f1\n",
        "\n",
        "# Find threshold to match target number of positives\n",
        "def find_threshold_for_target_positives(y_proba, target_positives, tolerance=10):\n",
        "    \"\"\"Find threshold that results in approximately target_positives number of positive predictions\"\"\"\n",
        "    # Sort probabilities in descending order\n",
        "    sorted_proba = np.sort(y_proba)[::-1]\n",
        "    \n",
        "    # Use the target_positives-th highest probability as threshold\n",
        "    if target_positives > len(y_proba):\n",
        "        target_positives = len(y_proba)\n",
        "    if target_positives < 0:\n",
        "        target_positives = 0\n",
        "    \n",
        "    threshold = sorted_proba[target_positives - 1] if target_positives > 0 else sorted_proba[0] + 0.001\n",
        "    \n",
        "    # Apply threshold\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "    actual_positives = y_pred.sum()\n",
        "    \n",
        "    # Fine-tune if needed\n",
        "    if abs(actual_positives - target_positives) > tolerance:\n",
        "        # Binary search for better threshold\n",
        "        low_threshold = 0.0\n",
        "        high_threshold = 1.0\n",
        "        best_threshold = threshold\n",
        "        best_diff = abs(actual_positives - target_positives)\n",
        "        \n",
        "        for _ in range(50):  # Max 50 iterations\n",
        "            mid_threshold = (low_threshold + high_threshold) / 2\n",
        "            y_pred_mid = (y_proba >= mid_threshold).astype(int)\n",
        "            mid_positives = y_pred_mid.sum()\n",
        "            diff = abs(mid_positives - target_positives)\n",
        "            \n",
        "            if diff < best_diff:\n",
        "                best_diff = diff\n",
        "                best_threshold = mid_threshold\n",
        "            \n",
        "            if mid_positives < target_positives:\n",
        "                high_threshold = mid_threshold\n",
        "            else:\n",
        "                low_threshold = mid_threshold\n",
        "            \n",
        "            if diff <= tolerance:\n",
        "                break\n",
        "        \n",
        "        threshold = best_threshold\n",
        "        y_pred = (y_proba >= threshold).astype(int)\n",
        "        actual_positives = y_pred.sum()\n",
        "    \n",
        "    return threshold, actual_positives\n",
        "\n",
        "# Find optimal threshold on validation set\n",
        "optimal_threshold_base, optimal_f1_base = find_optimal_threshold(y_val, y_val_pred_base_proba)\n",
        "\n",
        "# Convert to binary predictions\n",
        "y_train_pred_base = (y_train_pred_base_proba >= optimal_threshold_base).astype(int)\n",
        "y_val_pred_base = (y_val_pred_base_proba >= optimal_threshold_base).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "train_f1_base = f1_score(y_train, y_train_pred_base)\n",
        "val_f1_base = f1_score(y_val, y_val_pred_base)\n",
        "train_auc_base = roc_auc_score(y_train, y_train_pred_base_proba)\n",
        "val_auc_base = roc_auc_score(y_val, y_val_pred_base_proba)\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"BASE MODEL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Training F1: {train_f1_base:.6f}\")\n",
        "print(f\"Validation F1: {val_f1_base:.6f}\")\n",
        "print(f\"Training AUC: {train_auc_base:.6f}\")\n",
        "print(f\"Validation AUC: {val_auc_base:.6f}\")\n",
        "print(f\"Optimal threshold: {optimal_threshold_base:.4f}\")\n",
        "print(f\"Best iteration: {base_model.best_iteration}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance_base = pd.DataFrame({\n",
        "    'feature': X_train_scaled.columns,\n",
        "    'importance': base_model.feature_importance(importance_type='gain')\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(f\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance_base.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Feature Interaction Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "FEATURE INTERACTION TESTING\n",
            "================================================================================\n",
            "Testing interactions among top 50 features\n",
            "Total interactions to test: 820\n",
            "\n",
            "Testing pairwise feature interactions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing interactions:   4%|‚ñç         | 33/820 [00:28<12:14,  1.07interaction/s]"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 6: Feature Interaction Testing\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FEATURE INTERACTION TESTING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get top features for interaction testing (to reduce computation time)\n",
        "top_n_features = 50  # Test interactions among top 50 features\n",
        "top_features = feature_importance_base.head(top_n_features)['feature'].tolist()\n",
        "\n",
        "print(f\"Testing interactions among top {top_n_features} features\")\n",
        "print(f\"Total interactions to test: {len(top_features) * (len(top_features) - 1) // 2}\")\n",
        "\n",
        "# Function to test feature interactions\n",
        "def test_feature_interaction(X_train, X_val, y_train, y_val, feature1, feature2, base_f1):\n",
        "    \"\"\"Test interaction between two features\"\"\"\n",
        "    X_train_inter = X_train.copy()\n",
        "    X_val_inter = X_val.copy()\n",
        "    \n",
        "    # Create interaction feature (multiplication)\n",
        "    X_train_inter[f'{feature1}_x_{feature2}'] = X_train[feature1] * X_train[feature2]\n",
        "    X_val_inter[f'{feature1}_x_{feature2}'] = X_val[feature1] * X_val[feature2]\n",
        "    \n",
        "    # Train quick model\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': 31,\n",
        "        'learning_rate': 0.1,\n",
        "        'n_estimators': 500,\n",
        "        'verbose': -1,\n",
        "        'random_state': 42\n",
        "    }\n",
        "    \n",
        "    train_data_lgb = lgb.Dataset(X_train_inter, label=y_train)\n",
        "    val_data_lgb = lgb.Dataset(X_val_inter, label=y_val, reference=train_data_lgb)\n",
        "    \n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_data_lgb,\n",
        "        valid_sets=[val_data_lgb],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
        "    )\n",
        "    \n",
        "    y_val_pred_proba = model.predict(X_val_inter, num_iteration=model.best_iteration)\n",
        "    \n",
        "    # Find optimal threshold and calculate F1\n",
        "    opt_thresh, _ = find_optimal_threshold(y_val, y_val_pred_proba)\n",
        "    y_val_pred_binary = (y_val_pred_proba >= opt_thresh).astype(int)\n",
        "    val_f1 = f1_score(y_val, y_val_pred_binary)\n",
        "    \n",
        "    improvement = val_f1 - base_f1\n",
        "    return val_f1, improvement, f'{feature1}_x_{feature2}'\n",
        "\n",
        "# Test all pairwise interactions with progress bar\n",
        "print(\"\\nTesting pairwise feature interactions...\")\n",
        "interaction_results = []\n",
        "\n",
        "# Calculate total number of interactions\n",
        "total_interactions = len(top_features) * (len(top_features) - 1) // 2\n",
        "\n",
        "# Use tqdm for progress bar\n",
        "with tqdm(total=total_interactions, desc=\"Testing interactions\", unit=\"interaction\") as pbar:\n",
        "    for i, feat1 in enumerate(top_features):\n",
        "        for feat2 in top_features[i+1:]:\n",
        "            if feat1 != feat2:\n",
        "                try:\n",
        "                    f1, improvement, interaction_name = test_feature_interaction(\n",
        "                        X_train_scaled, X_val_scaled, y_train, y_val, \n",
        "                        feat1, feat2, val_f1_base\n",
        "                    )\n",
        "                    interaction_results.append({\n",
        "                        'feature1': feat1,\n",
        "                        'feature2': feat2,\n",
        "                        'interaction': interaction_name,\n",
        "                        'val_f1': f1,\n",
        "                        'improvement': improvement\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    tqdm.write(f\"Error testing {feat1} x {feat2}: {e}\")\n",
        "                finally:\n",
        "                    pbar.update(1)\n",
        "\n",
        "# Sort by improvement\n",
        "interaction_df = pd.DataFrame(interaction_results)\n",
        "interaction_df = interaction_df.sort_values('improvement', ascending=False)\n",
        "\n",
        "print(f\"\\nTested {len(interaction_df)} interactions\")\n",
        "print(f\"\\nTop 50 Best Interactions:\")\n",
        "print(interaction_df.head(50))\n",
        "\n",
        "# Select interactions that improve performance\n",
        "min_improvement = 0.001  # Minimum improvement threshold\n",
        "selected_interactions = interaction_df[interaction_df['improvement'] > min_improvement]\n",
        "\n",
        "print(f\"\\nSelected {len(selected_interactions)} interactions with improvement > {min_improvement}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Add Selected Interactions to Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 7: Add Selected Interactions to Features\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ADDING SELECTED INTERACTIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create new feature sets with interactions\n",
        "X_train_with_interactions = X_train_scaled.copy()\n",
        "X_val_with_interactions = X_val_scaled.copy()\n",
        "\n",
        "added_count = 0\n",
        "for _, row in selected_interactions.head(50).iterrows():  # Limit to top 50 interactions\n",
        "    feat1 = row['feature1']\n",
        "    feat2 = row['feature2']\n",
        "    interaction_name = row['interaction']\n",
        "    \n",
        "    if feat1 in X_train_scaled.columns and feat2 in X_train_scaled.columns:\n",
        "        X_train_with_interactions[interaction_name] = X_train_scaled[feat1] * X_train_scaled[feat2]\n",
        "        X_val_with_interactions[interaction_name] = X_val_scaled[feat1] * X_val_scaled[feat2]\n",
        "        added_count += 1\n",
        "\n",
        "print(f\"Added {added_count} interaction features\")\n",
        "print(f\"New feature count: {X_train_with_interactions.shape[1]} (was {X_train_scaled.shape[1]})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Hyperparameter Tuning with Optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 8: Hyperparameter Tuning with Optuna\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"HYPERPARAMETER TUNING WITH OPTUNA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"Optuna objective function for hyperparameter tuning - optimizes F1 score\"\"\"\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 10, 300),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n",
        "        'verbose': -1,\n",
        "        'random_state': 42,\n",
        "        'is_unbalance': True\n",
        "    }\n",
        "    \n",
        "    train_data_lgb = lgb.Dataset(X_train_with_interactions, label=y_train)\n",
        "    val_data_lgb = lgb.Dataset(X_val_with_interactions, label=y_val, reference=train_data_lgb)\n",
        "    \n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_data_lgb,\n",
        "        valid_sets=[val_data_lgb],\n",
        "        num_boost_round=2000,\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
        "            lgb.log_evaluation(period=0)\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    y_val_pred_proba = model.predict(X_val_with_interactions, num_iteration=model.best_iteration)\n",
        "    \n",
        "    # Find optimal threshold and calculate F1 score\n",
        "    opt_thresh, _ = find_optimal_threshold(y_val, y_val_pred_proba)\n",
        "    y_val_pred_binary = (y_val_pred_proba >= opt_thresh).astype(int)\n",
        "    f1 = f1_score(y_val, y_val_pred_binary)\n",
        "    \n",
        "    return f1\n",
        "\n",
        "# Run optimization\n",
        "print(\"Starting hyperparameter optimization...\")\n",
        "study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    sampler=TPESampler(seed=42)\n",
        ")\n",
        "\n",
        "n_trials = 100  # Number of trials for tuning\n",
        "study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "print(f\"\\nBest hyperparameters:\")\n",
        "print(study.best_params)\n",
        "print(f\"\\nBest validation F1: {study.best_value:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Train Final Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 9: Train Final Tuned Model\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING FINAL TUNED MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get best parameters\n",
        "best_params = study.best_params.copy()\n",
        "best_params.update({\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'verbose': -1,\n",
        "    'random_state': 42,\n",
        "    'is_unbalance': True,\n",
        "    'n_estimators': 10000  # High number of iterations\n",
        "})\n",
        "\n",
        "print(f\"Final model parameters: {best_params}\")\n",
        "\n",
        "# Train final model\n",
        "train_data_lgb = lgb.Dataset(X_train_with_interactions, label=y_train)\n",
        "val_data_lgb = lgb.Dataset(X_val_with_interactions, label=y_val, reference=train_data_lgb)\n",
        "\n",
        "final_model = lgb.train(\n",
        "    best_params,\n",
        "    train_data_lgb,\n",
        "    valid_sets=[train_data_lgb, val_data_lgb],\n",
        "    valid_names=['train', 'val'],\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=200, verbose=True),\n",
        "        lgb.log_evaluation(period=100)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Make predictions (probabilities)\n",
        "y_train_pred_final_proba = final_model.predict(X_train_with_interactions, num_iteration=final_model.best_iteration)\n",
        "y_val_pred_final_proba = final_model.predict(X_val_with_interactions, num_iteration=final_model.best_iteration)\n",
        "\n",
        "# Find optimal threshold for F1 score\n",
        "optimal_threshold_final, optimal_f1_final = find_optimal_threshold(y_val, y_val_pred_final_proba)\n",
        "\n",
        "# Convert to binary predictions\n",
        "y_train_pred_final = (y_train_pred_final_proba >= optimal_threshold_final).astype(int)\n",
        "y_val_pred_final = (y_val_pred_final_proba >= optimal_threshold_final).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "train_f1_final = f1_score(y_train, y_train_pred_final)\n",
        "val_f1_final = f1_score(y_val, y_val_pred_final)\n",
        "train_auc_final = roc_auc_score(y_train, y_train_pred_final_proba)\n",
        "val_auc_final = roc_auc_score(y_val, y_val_pred_final_proba)\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL MODEL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Training F1: {train_f1_final:.6f}\")\n",
        "print(f\"Validation F1: {val_f1_final:.6f}\")\n",
        "print(f\"Training AUC: {train_auc_final:.6f}\")\n",
        "print(f\"Validation AUC: {val_auc_final:.6f}\")\n",
        "print(f\"Optimal threshold: {optimal_threshold_final:.4f}\")\n",
        "print(f\"Best iteration: {final_model.best_iteration}\")\n",
        "print(f\"\\nImprovement over base model (F1): {val_f1_final - val_f1_base:.6f}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance_final = pd.DataFrame({\n",
        "    'feature': X_train_with_interactions.columns,\n",
        "    'importance': final_model.feature_importance(importance_type='gain')\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(f\"\\nTop 20 Most Important Features (Final Model):\")\n",
        "print(feature_importance_final.head(20))\n",
        "\n",
        "# Save feature importance\n",
        "feature_importance_final.to_csv('lightgbm_feature_importance.csv', index=False)\n",
        "print(f\"\\nFeature importance saved to: lightgbm_feature_importance.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Model Comparison Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 10: Model Comparison Summary\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': ['Base LightGBM', 'Tuned LightGBM with Interactions'],\n",
        "    'Training F1': [train_f1_base, train_f1_final],\n",
        "    'Validation F1': [val_f1_base, val_f1_final],\n",
        "    'Training AUC': [train_auc_base, train_auc_final],\n",
        "    'Validation AUC': [val_auc_base, val_auc_final],\n",
        "    'F1 Improvement': [0, val_f1_final - val_f1_base]\n",
        "})\n",
        "\n",
        "print(comparison.to_string(index=False))\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features_plot = feature_importance_final.head(50)\n",
        "plt.barh(range(len(top_features_plot)), top_features_plot['importance'].values)\n",
        "plt.yticks(range(len(top_features_plot)), top_features_plot['feature'].values)\n",
        "plt.xlabel('Feature Importance (Gain)')\n",
        "plt.title('Top 20 Feature Importance - Final LightGBM Model')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig('lightgbm_feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "print(f\"\\nFeature importance plot saved to: lightgbm_feature_importance.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Load Test Data and Generate Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 11: Load Test Data\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING TEST DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv('Data/Testing_TriGuard.csv')\n",
        "test_original = test_df.copy()\n",
        "\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "print(f\"\\nTest columns: {list(test_df.columns)}\")\n",
        "\n",
        "# Store claim numbers for submission\n",
        "test_claim_numbers = test_df['claim_number'].copy()\n",
        "\n",
        "# Separate features (no target in test data)\n",
        "X_test_raw = test_df.drop(['claim_number'], axis=1, errors='ignore')\n",
        "\n",
        "print(f\"\\nTest features shape: {X_test_raw.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 12: Preprocess Test Data (Same as Training)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREPROCESSING TEST DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Apply the same preprocessing function\n",
        "X_test_processed, _, _ = preprocess_features(X_test_raw)\n",
        "\n",
        "# Ensure test set has the same columns as training\n",
        "# Add missing columns as zeros\n",
        "for col in X_train_processed.columns:\n",
        "    if col not in X_test_processed.columns:\n",
        "        X_test_processed[col] = 0\n",
        "\n",
        "# Remove columns that don't exist in training\n",
        "X_test_processed = X_test_processed[X_train_processed.columns]\n",
        "\n",
        "print(f\"Test features after preprocessing: {X_test_processed.shape}\")\n",
        "print(f\"Training features shape: {X_train_processed.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 13: Scale Test Data\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SCALING TEST DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Use the same scaler fitted on training data\n",
        "X_test_scaled = pd.DataFrame(\n",
        "    scaler.transform(X_test_processed),\n",
        "    columns=X_test_processed.columns,\n",
        "    index=X_test_processed.index\n",
        ")\n",
        "\n",
        "print(f\"Scaled test features shape: {X_test_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 14: Add Interaction Features to Test Data\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ADDING INTERACTION FEATURES TO TEST DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create test feature set with interactions (same as training)\n",
        "X_test_with_interactions = X_test_scaled.copy()\n",
        "\n",
        "added_count = 0\n",
        "for _, row in selected_interactions.head(30).iterrows():  # Same interactions as training\n",
        "    feat1 = row['feature1']\n",
        "    feat2 = row['feature2']\n",
        "    interaction_name = row['interaction']\n",
        "    \n",
        "    if feat1 in X_test_scaled.columns and feat2 in X_test_scaled.columns:\n",
        "        X_test_with_interactions[interaction_name] = X_test_scaled[feat1] * X_test_scaled[feat2]\n",
        "        added_count += 1\n",
        "\n",
        "print(f\"Added {added_count} interaction features to test data\")\n",
        "print(f\"Test features with interactions: {X_test_with_interactions.shape[1]} features\")\n",
        "\n",
        "# Ensure all columns match training data\n",
        "for col in X_train_with_interactions.columns:\n",
        "    if col not in X_test_with_interactions.columns:\n",
        "        X_test_with_interactions[col] = 0\n",
        "\n",
        "# Select only columns that exist in training\n",
        "X_test_with_interactions = X_test_with_interactions[X_train_with_interactions.columns]\n",
        "\n",
        "print(f\"Final test features shape: {X_test_with_interactions.shape}\")\n",
        "print(f\"Training features shape: {X_train_with_interactions.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 15: Select Top 50 Features\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SELECTING TOP 50 FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get top 50 features based on feature importance from final model\n",
        "top_50_features = feature_importance_final.head(50)['feature'].tolist()\n",
        "\n",
        "print(f\"Top 50 features selected:\")\n",
        "print(top_50_features)\n",
        "\n",
        "# Select these features for both training and test\n",
        "X_train_top50 = X_train_with_interactions[top_50_features]\n",
        "X_test_top50 = X_test_with_interactions[top_50_features]\n",
        "\n",
        "print(f\"\\nTraining features (top 50): {X_train_top50.shape}\")\n",
        "print(f\"Test features (top 50): {X_test_top50.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 16: Retrain Model on Top 50 Features\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RETRAINING MODEL ON TOP 50 FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Use the best parameters from tuning\n",
        "best_params_top50 = best_params.copy()\n",
        "\n",
        "print(f\"Training with parameters: {best_params_top50}\")\n",
        "\n",
        "# Create LightGBM datasets with top 50 features\n",
        "train_data_lgb_top50 = lgb.Dataset(X_train_top50, label=y_train)\n",
        "val_data_lgb_top50 = lgb.Dataset(X_val_with_interactions[top_50_features], label=y_val, reference=train_data_lgb_top50)\n",
        "\n",
        "# Retrain model on top 50 features\n",
        "final_model_top50 = lgb.train(\n",
        "    best_params_top50,\n",
        "    train_data_lgb_top50,\n",
        "    valid_sets=[train_data_lgb_top50, val_data_lgb_top50],\n",
        "    valid_names=['train', 'val'],\n",
        "    callbacks=[\n",
        "        lgb.early_stopping(stopping_rounds=200, verbose=True),\n",
        "        lgb.log_evaluation(period=100)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_val_pred_top50_proba = final_model_top50.predict(X_val_with_interactions[top_50_features], num_iteration=final_model_top50.best_iteration)\n",
        "\n",
        "# Find optimal threshold for F1 score\n",
        "optimal_threshold_top50, optimal_f1_top50 = find_optimal_threshold(y_val, y_val_pred_top50_proba)\n",
        "\n",
        "# Convert to binary predictions\n",
        "y_val_pred_top50 = (y_val_pred_top50_proba >= optimal_threshold_top50).astype(int)\n",
        "val_f1_top50 = f1_score(y_val, y_val_pred_top50)\n",
        "val_auc_top50 = roc_auc_score(y_val, y_val_pred_top50_proba)\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"TOP 50 FEATURE MODEL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Validation F1 (top 50 features): {val_f1_top50:.6f}\")\n",
        "print(f\"Validation AUC (top 50 features): {val_auc_top50:.6f}\")\n",
        "print(f\"Optimal threshold: {optimal_threshold_top50:.4f}\")\n",
        "print(f\"Best iteration: {final_model_top50.best_iteration}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 17: Generate Predictions on Test Data\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERATING PREDICTIONS ON TEST DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Make predictions on test data (probabilities)\n",
        "test_predictions_proba = final_model_top50.predict(X_test_top50, num_iteration=final_model_top50.best_iteration)\n",
        "\n",
        "# Target number of positives from Kaggle probing: ~2778 (23.15% of 12000)\n",
        "target_positives = 2778\n",
        "\n",
        "# Find threshold that results in approximately target_positives\n",
        "threshold_for_target, actual_positives = find_threshold_for_target_positives(\n",
        "    test_predictions_proba, \n",
        "    target_positives, \n",
        "    tolerance=5\n",
        ")\n",
        "\n",
        "# Also check F1-optimized threshold for comparison\n",
        "test_predictions_f1 = (test_predictions_proba >= optimal_threshold_top50).astype(int)\n",
        "positives_f1 = test_predictions_f1.sum()\n",
        "\n",
        "print(f\"Test predictions shape: {test_predictions_proba.shape}\")\n",
        "print(f\"\\nThreshold Selection:\")\n",
        "print(f\"  F1-optimized threshold: {optimal_threshold_top50:.6f} -> {positives_f1} positives ({positives_f1/len(test_predictions_proba)*100:.2f}%)\")\n",
        "print(f\"  Target-matching threshold: {threshold_for_target:.6f} -> {actual_positives} positives ({actual_positives/len(test_predictions_proba)*100:.2f}%)\")\n",
        "print(f\"  Target: {target_positives} positives (23.15%)\")\n",
        "print(f\"  Difference from target: {actual_positives - target_positives} instances\")\n",
        "\n",
        "# Use target-matching threshold for final predictions\n",
        "test_predictions = (test_predictions_proba >= threshold_for_target).astype(int)\n",
        "\n",
        "print(f\"\\nFinal binary predictions:\")\n",
        "print(f\"  Range: [{test_predictions.min()}, {test_predictions.max()}]\")\n",
        "print(f\"  Predicted positives: {test_predictions.sum()} ({test_predictions.sum()/len(test_predictions)*100:.2f}%)\")\n",
        "print(f\"  Predicted negatives: {(test_predictions == 0).sum()} ({(test_predictions == 0).sum()/len(test_predictions)*100:.2f}%)\")\n",
        "print(f\"\\nFirst 10 binary predictions:\")\n",
        "print(test_predictions[:10])\n",
        "print(f\"\\nFirst 10 probabilities:\")\n",
        "print(test_predictions_proba[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 18: Generate Submission CSV\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERATING SUBMISSION CSV\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create submission DataFrame with binary predictions (0 or 1)\n",
        "submission = pd.DataFrame({\n",
        "    'claim_number': test_claim_numbers,\n",
        "    'subrogation': test_predictions.astype(int)  # Ensure integer type\n",
        "})\n",
        "\n",
        "# Save submission file\n",
        "submission_filename = 'lightgbm_submission.csv'\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"Submission file saved: {submission_filename}\")\n",
        "print(f\"\\nSubmission statistics:\")\n",
        "print(f\"  Shape: {submission.shape}\")\n",
        "print(f\"  Prediction range: [{submission['subrogation'].min()}, {submission['subrogation'].max()}]\")\n",
        "print(f\"  Predicted positives: {submission['subrogation'].sum()} ({submission['subrogation'].sum()/len(submission)*100:.2f}%)\")\n",
        "print(f\"  Predicted negatives: {(submission['subrogation'] == 0).sum()} ({(submission['subrogation'] == 0).sum()/len(submission)*100:.2f}%)\")\n",
        "print(f\"  Expected positives (from Kaggle): ~2,778 (23.15%)\")\n",
        "print(f\"  Difference: {submission['subrogation'].sum() - 2778} instances\")\n",
        "print(f\"\\nFirst 10 rows:\")\n",
        "print(submission.head(10))\n",
        "print(f\"\\nLast 10 rows:\")\n",
        "print(submission.tail(10))\n",
        "\n",
        "# Verify submission format matches sample\n",
        "sample_submission = pd.read_csv('Data/sample_submission.csv')\n",
        "print(f\"\\nSample submission format:\")\n",
        "print(sample_submission.head())\n",
        "print(f\"\\nSubmission format matches: {list(submission.columns) == list(sample_submission.columns)}\")\n",
        "print(f\"Values are binary (0 or 1): {submission['subrogation'].isin([0, 1]).all()}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
