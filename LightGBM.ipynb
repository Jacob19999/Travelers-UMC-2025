{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPQfQ7lz8tjp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LU0nJNBv8v9d"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "train_df = pd.read_csv('/content/Training_TriGuard.csv')\n",
        "test_df = pd.read_csv('/content/Testing_TriGuard.csv')\n",
        "sample_submission = pd.read_csv('/content/sample_submission.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IQjxSRLx8xhG"
      },
      "outputs": [],
      "source": [
        "# prepare features from target\n",
        "target_col = 'subrogation'\n",
        "id_col = 'claim_number'\n",
        "\n",
        "# drop rows where target is missing\n",
        "train_df = train_df.dropna(subset=[target_col])\n",
        "\n",
        "y = train_df[target_col]\n",
        "X = train_df.drop(columns=[target_col])\n",
        "X_test = test_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4F4blVjI8zw8"
      },
      "outputs": [],
      "source": [
        "# train/validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8JkACmWT81Nd"
      },
      "outputs": [],
      "source": [
        "#encode categorical columns\n",
        "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "num_cols = X_train.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "\n",
        "# Fit-transform on training\n",
        "X_train_cat = pd.DataFrame(\n",
        "    encoder.fit_transform(X_train[cat_cols]),\n",
        "    columns=encoder.get_feature_names_out(cat_cols),\n",
        "    index=X_train.index\n",
        ")\n",
        "X_val_cat = pd.DataFrame(\n",
        "    encoder.transform(X_val[cat_cols]),\n",
        "    columns=encoder.get_feature_names_out(cat_cols),\n",
        "    index=X_val.index\n",
        ")\n",
        "X_test_cat = pd.DataFrame(\n",
        "    encoder.transform(X_test[cat_cols]),\n",
        "    columns=encoder.get_feature_names_out(cat_cols),\n",
        "    index=X_test.index\n",
        ")\n",
        "\n",
        "# Combine categorical + numeric features\n",
        "X_train_encoded = pd.concat([X_train[num_cols].reset_index(drop=True),\n",
        "                             X_train_cat.reset_index(drop=True)], axis=1)\n",
        "X_val_encoded = pd.concat([X_val[num_cols].reset_index(drop=True),\n",
        "                           X_val_cat.reset_index(drop=True)], axis=1)\n",
        "X_test_encoded = pd.concat([X_test[num_cols].reset_index(drop=True),\n",
        "                            X_test_cat.reset_index(drop=True)], axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDvdrnfP82ad",
        "outputId": "aaacf2f0-0b9e-4f31-db22-d79bfd33f816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After SMOTE → Positive class proportion: 0.333\n"
          ]
        }
      ],
      "source": [
        "# SMOTE\n",
        "sm = SMOTE(random_state=42, sampling_strategy=0.5)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train_encoded, y_train)\n",
        "print(f\"After SMOTE → Positive class proportion: {y_train_res.mean():.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnMDQmiE83MY",
        "outputId": "6c012d37-fd83-4548-be58-7423e388c919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Fold 1 =====\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 4443, number of negative: 8885\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062321 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14782\n",
            "[LightGBM] [Info] Number of data points in the train set: 13328, number of used features: 448\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333358 -> initscore=-0.693035\n",
            "[LightGBM] [Info] Start training from score -0.693035\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[158]\tvalid_0's binary_logloss: 0.340745\n",
            "\n",
            "===== Fold 2 =====\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 4443, number of negative: 8885\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.137387 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14625\n",
            "[LightGBM] [Info] Number of data points in the train set: 13328, number of used features: 450\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333358 -> initscore=-0.693035\n",
            "[LightGBM] [Info] Start training from score -0.693035\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[164]\tvalid_0's binary_logloss: 0.342888\n",
            "\n",
            "===== Fold 3 =====\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 8886\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068030 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14851\n",
            "[LightGBM] [Info] Number of data points in the train set: 13328, number of used features: 463\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333283 -> initscore=-0.693372\n",
            "[LightGBM] [Info] Start training from score -0.693372\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[140]\tvalid_0's binary_logloss: 0.356121\n",
            "\n",
            "===== Fold 4 =====\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 8886\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059017 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14824\n",
            "[LightGBM] [Info] Number of data points in the train set: 13328, number of used features: 457\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333283 -> initscore=-0.693372\n",
            "[LightGBM] [Info] Start training from score -0.693372\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[162]\tvalid_0's binary_logloss: 0.34542\n",
            "\n",
            "===== Fold 5 =====\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 4442, number of negative: 8886\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050561 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14788\n",
            "[LightGBM] [Info] Number of data points in the train set: 13328, number of used features: 449\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333283 -> initscore=-0.693372\n",
            "[LightGBM] [Info] Start training from score -0.693372\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[133]\tvalid_0's binary_logloss: 0.331355\n"
          ]
        }
      ],
      "source": [
        "# Cross validate LIGHTGBM\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "val_preds_cv = np.zeros(len(X_val_encoded))\n",
        "test_preds_cv = np.zeros(len(X_test_encoded))\n",
        "\n",
        "# Track F1 scores for each fold\n",
        "fold_f1_scores = []\n",
        "fold_numbers = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_res, y_train_res)):\n",
        "    print(f\"\\n===== Fold {fold + 1} =====\")\n",
        "    X_tr, X_vl = X_train_res.iloc[train_idx], X_train_res.iloc[val_idx]\n",
        "    y_tr, y_vl = y_train_res.iloc[train_idx], y_train_res.iloc[val_idx]\n",
        "\n",
        "    model = lgb.LGBMClassifier(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=31,\n",
        "        colsample_bytree=0.8,\n",
        "        subsample=0.8,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_vl, y_vl)],\n",
        "        eval_metric='f1',\n",
        "        callbacks=[early_stopping(stopping_rounds=50, verbose=True)]\n",
        "    )\n",
        "\n",
        "    # Get predictions for this fold on validation set\n",
        "    val_pred_fold = model.predict_proba(X_val_encoded)[:, 1]\n",
        "    test_pred_fold = model.predict_proba(X_test_encoded)[:, 1]\n",
        "    \n",
        "    # Find best threshold for this fold's validation predictions\n",
        "    thresholds = np.linspace(0.1, 0.9, 50)\n",
        "    f1_scores_fold = [f1_score(y_val, (val_pred_fold > t).astype(int)) for t in thresholds]\n",
        "    best_thresh_fold = thresholds[np.argmax(f1_scores_fold)]\n",
        "    best_f1_fold = max(f1_scores_fold)\n",
        "    \n",
        "    # Store F1 score for this fold\n",
        "    fold_f1_scores.append(best_f1_fold)\n",
        "    fold_numbers.append(fold + 1)\n",
        "    \n",
        "    print(f\"Fold {fold + 1} - Best Threshold: {best_thresh_fold:.3f}, F1 Score: {best_f1_fold:.4f}\")\n",
        "\n",
        "    val_preds_cv += val_pred_fold / kf.n_splits\n",
        "    test_preds_cv += test_pred_fold / kf.n_splits\n",
        "\n",
        "# Calculate overall F1 score\n",
        "thresholds_overall = np.linspace(0.1, 0.9, 50)\n",
        "f1_scores_overall = [f1_score(y_val, (val_preds_cv > t).astype(int)) for t in thresholds_overall]\n",
        "best_f1_overall = max(f1_scores_overall)\n",
        "fold_f1_scores.append(best_f1_overall)\n",
        "fold_numbers.append('Overall')\n",
        "\n",
        "print(f\"\\n===== Summary =====\")\n",
        "print(f\"Individual Fold F1 Scores: {[f'{f:.4f}' for f in fold_f1_scores[:-1]]}\")\n",
        "print(f\"Overall F1 Score: {best_f1_overall:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS3epQE984rW",
        "outputId": "ae9a34d6-0a25-4645-8d91-436e3fcab923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Threshold = 0.296 | F1 = 0.5739\n"
          ]
        }
      ],
      "source": [
        "#threshold F1\n",
        "thresholds = np.linspace(0.1, 0.9, 50)\n",
        "f1_scores = [f1_score(y_val, (val_preds_cv > t).astype(int)) for t in thresholds]\n",
        "best_thresh = thresholds[np.argmax(f1_scores)]\n",
        "print(f\"\\nBest Threshold = {best_thresh:.3f} | F1 = {max(f1_scores):.4f}\")\n",
        "\n",
        "# Create bar chart comparing F1 scores across folds\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(range(len(fold_f1_scores)), fold_f1_scores, \n",
        "               color=['steelblue'] * (len(fold_f1_scores) - 1) + ['darkorange'])\n",
        "\n",
        "# Customize the chart\n",
        "plt.xlabel('Fold Number', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "plt.title('F1 Score Comparison Across Cross-Validation Folds', fontsize=14, fontweight='bold')\n",
        "plt.xticks(range(len(fold_f1_scores)), fold_numbers, fontsize=10)\n",
        "plt.ylim([min(fold_f1_scores) * 0.95, max(fold_f1_scores) * 1.05])\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, score) in enumerate(zip(bars, fold_f1_scores)):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
        "             f'{score:.4f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Add legend\n",
        "legend_elements = [Patch(facecolor='steelblue', label='Individual Fold F1'),\n",
        "                   Patch(facecolor='darkorange', label='Overall F1')]\n",
        "plt.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print statistics\n",
        "print(f\"\\nF1 Score Statistics:\")\n",
        "print(f\"  Mean (Folds 1-5): {np.mean(fold_f1_scores[:-1]):.4f}\")\n",
        "print(f\"  Std Dev (Folds 1-5): {np.std(fold_f1_scores[:-1]):.4f}\")\n",
        "print(f\"  Min: {np.min(fold_f1_scores[:-1]):.4f}\")\n",
        "print(f\"  Max: {np.max(fold_f1_scores[:-1]):.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHL4lNqpAe5F",
        "outputId": "59048acf-bad6-4eb8-915d-cf33e92c1e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8938    0.7944    0.8412      2777\n",
            "         1.0     0.4956    0.6817    0.5739       823\n",
            "\n",
            "    accuracy                         0.7686      3600\n",
            "   macro avg     0.6947    0.7380    0.7075      3600\n",
            "weighted avg     0.8028    0.7686    0.7801      3600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Final evaluation\n",
        "val_final = (val_preds_cv > best_thresh).astype(int)\n",
        "print(\"\\nValidation Results:\")\n",
        "print(classification_report(y_val, val_final, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaLcck7YAgk4",
        "outputId": "c9f2096f-9811-4b25-ff2d-2362936085da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Submission file created: 'submission.csv'\n",
            "   claim_number  subrogation\n",
            "0       3126034            0\n",
            "1       7380142            0\n",
            "2       4655051            0\n",
            "3       6728725            1\n",
            "4       9848460            1\n"
          ]
        }
      ],
      "source": [
        "#submission\n",
        "submission = pd.DataFrame({\n",
        "    id_col: test_df[id_col],\n",
        "    target_col: (test_preds_cv > best_thresh).astype(int)\n",
        "})\n",
        "\n",
        "# Ensure claim_number column exists\n",
        "if id_col not in submission.columns:\n",
        "    raise KeyError(f\"'{id_col}' column not found in submission!\")\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"\\n✅ Submission file created: 'submission.csv'\")\n",
        "print(submission.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0dNpdG2KGrE",
        "outputId": "a416cf0e-73c1-43c4-917d-ab77c7beb63b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
